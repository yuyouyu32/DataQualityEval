import json
import re
from typing import List, Tuple

import numpy as np
import pandas as pd

from config import logging
from Models.models import Model
from Regression.regressioner import Regressioner

logger = logging.getLogger(__name__)


class RuleJudger(Model):
    def __init__(self, data_path, drop_columns, target_columns, regressioner: Regressioner):
        super().__init__(data_path, drop_columns, target_columns)
        self.drop_columns = drop_columns
        self.original_data = pd.read_excel(data_path)
        self.thresholds = self.get_column_thresholds()
        self.feature_columns = list(self.data.data.drop(columns=target_columns).columns)
        self.regressioner = regressioner
        logger.info("RuleJudger initialized.")
        
    @staticmethod
    def parse_elements(composition):
        pattern = r"\(([A-Za-z\d.]+)\)([\d.]+)|([A-Z][a-z]*)([\d.]+)?"
        matches = re.findall(pattern, composition)
        elements = {}
        for match in matches:
            if match[0]:  # å¦‚æœæœ‰æ‹¬å·
                sub_scale_factor = sum(float(x[1]) if x[1] else 1 for x in re.findall(r"([A-Z][a-z]*)([\d.]+)?", match[0]))
                scale_factor = float(match[1]) / sub_scale_factor
                sub_matches = re.findall(r"([A-Z][a-z]*)([\d.]+)?", match[0])
                for sub_match in sub_matches:
                    if sub_match[0] not in elements:
                        elements[sub_match[0]] = float(sub_match[1]) * scale_factor if sub_match[1] else scale_factor
            elif match[2]:  # å¦‚æœæ²¡æœ‰æ‹¬å·
                if match[2] not in elements:
                    elements[match[2]] = float(match[3]) if match[3] else 1
        sorted_elements = {key: value for key, value in sorted(elements.items(), key=lambda item: item[1], reverse=True)}
        element_strings = [f"{element}{round(value,2)}" for element, value in sorted_elements.items()]
        chem = "".join(element_strings)
        return elements, chem
    
    def get_column_thresholds(self):
        thresholds = {}
        for column in self.data.data.columns:
            thresholds[column] = int(self.data.data[column].min()), int(self.data.data[column].max())
        return thresholds 
    
    def judge_composition(self, elements: dict, chem: str) -> Tuple[str, str]:
        check_results = []
        if sum(elements.values()) != 100:
            check_results.append({'error': f'âŒ BMGsçš„å…ƒç´ æ€»å’Œä¸ç­‰äº100ï¼Œè¯·æ£€æŸ¥æˆ–ä½¿ç”¨ä¸‹é¢ä¿®æ­£çš„æˆåˆ†ï¼Œç›®å‰è§£æçš„BMGsæˆåˆ†ä¸º{chem}ï¼Œå»ºè®®åˆ é™¤ä¸­æ‹¬å·ç­‰å¤æ‚è®¡ç®—æ–¹å¼ï¼Œç›´æ¥è¾“å…¥å…ƒç´ ç™¾åˆ†æ¯”ï¼Œå¦‚`Al20Cu80`ã€‚'})
            total = sum(elements.values())
            elements = {key: round(100 * value / total, 2) for key, value in elements.items()}
            check_results.append({'warning': f'âš ï¸ BMGsçš„å…ƒç´ æ€»å’Œä¸ç­‰äº100ï¼Œå·²å¯åŠ¨è‡ªåŠ¨ä¿®æ­£ï¼Œä¿®æ­£åçš„BMGsæˆåˆ†ä¸º{elements}ã€‚'})
        else:
            check_results.append({'info': f'âœ… BMGsçš„å…ƒç´ æ€»å’Œç­‰äº100ï¼ŒBMGsæˆåˆ†ä¸º{elements}ã€‚'})
        return check_results, elements, chem

    def get_composition_features(self, elements: dict) -> np.ndarray:
        x = np.zeros(len(self.feature_columns))
        for element, value in elements.items():
            if element in self.feature_columns:
                x[self.feature_columns.index(element)] = value
        return x
        
    def judge_targets(self, input_point: dict, x: np.ndarray) -> List[dict]:
        check_results = []
        for column in self.target_columns:
            # æ•°æ®ä¸å­˜åœ¨æˆ–è€…ä¸ºç©ºæˆ–è€…ä¸æ˜¯æ•°å­—, æ•°å­—æ˜¯æµ®ç‚¹æ•°
            try:
                input_point[column] = float(input_point[column])
                logger.info(f"column: {column} is not numeric")
            except:
                input_point[column] = ""
            if column not in input_point or not input_point[column]:
                predicted_value = round(self.regressioner.predict(x, column), 2)
                check_results.append({'warning': f'âš ï¸ {column}çš„æ•°æ®ä¸å­˜åœ¨æˆ–è€…ä¸ºç©ºæˆ–è€…ä¸æ˜¯æ•°å­—ï¼Œå·²å¯åŠ¨è‡ªåŠ¨é¢„æµ‹ï¼Œé¢„æµ‹å€¼ä¸º{predicted_value}ã€‚'})
                input_point[f"{column}(predicted)"] = predicted_value
            else:
                value = round(float(input_point[column]), 2)
                min_value, max_value = self.thresholds[column]
                if value < min_value:
                    check_results.append({'warinig': f'âš ï¸ {column}çš„æ•°æ®ä¸åœ¨æ•°æ®é›†çš„åˆç†èŒƒå›´å†…ï¼Œ{column}ä¸º{value}ï¼Œæ•°æ®é›†ä¸­çš„æœ€å°å€¼ä¸º{min_value}ï¼Œè¯·æ£€æŸ¥ã€‚'})
                elif value > max_value:
                    check_results.append({'warinig': f'âš ï¸ {column}çš„æ•°æ®ä¸åœ¨æ•°æ®é›†çš„åˆç†èŒƒå›´å†…ï¼Œ{column}ä¸º{value}ï¼Œæ•°æ®é›†ä¸­çš„æœ€å¤§å€¼ä¸º{max_value}ï¼Œè¯·æ£€æŸ¥ã€‚'})
                else:
                    check_results.append({'info': f'âœ… {column}çš„æ•°æ®åœ¨åˆç†èŒƒå›´å†…ï¼Œ{column}ä¸º{value}ã€‚'})
                
        return check_results, input_point
    
    def find_similar_points(self, x):
        check_results = []
        all_features = self.data.data.drop(columns=self.target_columns).to_numpy()
        distances = np.linalg.norm(all_features - x, axis=1)
        within_threshold_indices = np.where(distances <= 10)[0]
        similar_points = [(index, distances[index]) for index in within_threshold_indices]
        similar_points = sorted(similar_points, key=lambda point: point[1])
        indexes = [point[0] for point in similar_points]
        if len(indexes) > 0:
            similar_bmgs = "ğŸ“Œ åœ¨æ•°æ®é›†ä¸­æ‰¾åˆ°äº†ä»¥ä¸‹ç›¸ä¼¼çš„BMGsï¼š"
            for index in indexes:
                BMGs = self.original_data.loc[index, 'BMGs']
                similar_bmgs += f"\n    - BMGs: {BMGs}"
                for target_column in self.target_columns:
                    if not np.isnan(self.original_data.loc[index, target_column]):
                        similar_bmgs += f" {target_column}: {self.original_data.loc[index, target_column]}"
            check_results.append({'info': similar_bmgs})
        else:
            similar_bmgs = None
            check_results.append({'warning': f'âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä¸è¾“å…¥ç‚¹ç›¸ä¼¼çš„ç‚¹ã€‚'})
        return check_results, similar_bmgs
    
    @staticmethod
    def format_messages(messages):
        md_string = ""
        
        for msg in messages:
            # å¤„ç† info ä¿¡æ¯
            if 'info' in msg:
                md_string += f"ğŸŸ¢ **Info**: {msg['info']}\n\n"
            
            # å¤„ç† error ä¿¡æ¯
            if 'error' in msg:
                md_string += f"ğŸ”´ **Error**: {msg['error']}\n\n"
            
            # å¤„ç† warning ä¿¡æ¯
            if 'warning' in msg:
                md_string += f"ğŸŸ¡ **Warning**: {msg['warning']}\n\n"
        
        return md_string
    
    def construct_full_x_y(self, x, input_point):
        results = {}
        for target_name in self.target_columns:
            if f"{target_name}(predicted)" in input_point:
                results[target_name] = input_point[f"{target_name}(predicted)"]
            else:
                results[target_name] = input_point[target_name]
                
        for column_name, value in zip(self.feature_columns, x):
            results[column_name] = value
        all_columns = self.original_data.drop(columns=self.drop_columns).columns
        y = np.array([results[column] for column in all_columns if column in self.target_columns])
        full_x_y = np.array([results[column] for column in all_columns])
        return full_x_y, y
    
    def judge(self, input_point):
        """
        input_point:
        {
            "Composition": "Al20(CoCrCuFeMnNiTiV)80",
            "Dmax(mm)": "13",
            "Tg(K)": "345",
            "Tx(K)": "467",
            "Tl(K)": "831",
            "yield(MPa)": "1234",
            "Modulus(GPa)": "164",
            "Î•(%)": "23"
        }
        """
        all_check_results = []
        elements, chem = self.parse_elements(input_point["Composition"])
        composition_check_results, elements, chem = self.judge_composition(elements, chem)
        x = self.get_composition_features(elements)
        all_check_results.extend(composition_check_results)
        targets_check_results, input_point = self.judge_targets(input_point, x)
        all_check_results.extend(targets_check_results)
        similar_points_results, similar_bmgs = self.find_similar_points(x)
        all_check_results.extend(similar_points_results)
        md_str = self.format_messages(all_check_results)
        full_x_y, y = self.construct_full_x_y(x, input_point)
        return md_str, input_point, x, y, full_x_y, similar_bmgs
    
def unit_test():
    data_path = '../data/ALL_data_grouped_processed.xlsx'  # Replace with your file path
    drop_columns = ['BMGs', "Chemical composition", 'cls_label']
    target_columns = ['Tg(K)', 'Tx(K)', 'Tl(K)', 'Dmax(mm)', 'yield(MPa)', 'Modulus(GPa)', 'Î•(%)']
    regressioner = Regressioner(data_path, drop_columns, target_columns)
    judger = RuleJudger(data_path, drop_columns, target_columns, regressioner)
    test_point = {
        "Composition": "Al20(CoCrCuFeMnNiTiV)80",
        "Dmax(mm)": "xx",
        "Tg(K)": "xxx",
        "Tx(K)": "xxx",
        "Tl(K)": "xxx",
        "yield(MPa)": "1465",
        "Modulus(GPa)": "190",
        "Î•(%)": "2.35"
    }
    md_str, input_point, x, y, full_x_y, similiar_bmg = judger.judge(test_point)
    print(md_str)
    print(input_point)
    print(x)
    print(y)
    print(full_x_y)
    print(similiar_bmg)

# python -m RuleJudge.judger
if __name__ == "__main__":
    unit_test()